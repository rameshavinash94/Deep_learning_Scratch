{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_Scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMj0xjKcTOO2k0B1L2wv2FK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rameshavinash94/Deep_learning_Scratch/blob/main/DeepLearning_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Numpy**"
      ],
      "metadata": {
        "id": "BfDL5jE4J9vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "yCS1TNLaQ0dR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearActivation:\n",
        "  def forward(self,inputs):\n",
        "    # Just remember values self.inputs = inputs self.output = inputs (y=f(x))\n",
        "    self.inputs=inputs\n",
        "    self.outputs=self.inputs\n",
        "\n",
        "  def backward(self,dvalues):\n",
        "    self.dinputs=dvalues.copy()"
      ],
      "metadata": {
        "id": "vw4wCddq52WJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MSE:\n",
        "  #forward pass\n",
        "  def forward(self,ypred,y):\n",
        "    loss=np.mean((y-ypred)**2)\n",
        "    return loss\n",
        "  \n",
        "  #backward pass\n",
        "  def backward(self,dvalues,ytrue):\n",
        "    #count of data samples\n",
        "    samples=len(dvalues)\n",
        "    outputs=len(dvalues[0])\n",
        "    self.dinputs = (-2 * (ytrue - dvalues)) / outputs\n",
        "    self.dinputs = self.dinputs/samples"
      ],
      "metadata": {
        "id": "F7m1t1GMYs4i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu:\n",
        "  #forward pass\n",
        "  def forward(self,inputs):\n",
        "    self.inputs=inputs\n",
        "    self.output=np.maximum(self.inputs*0.03,self.inputs)\n",
        "  \n",
        "  #backward pass\n",
        "  def backward(self,dvalues):\n",
        "    self.dinputs = dvalues.copy()\n",
        "    self.dinputs[self.dinputs <= 0 ]=0"
      ],
      "metadata": {
        "id": "P-ys066zIbXH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD optimizer\n",
        "class Optimizer_SGD:\n",
        "\n",
        "    # Initialize optimizer - set settings,\n",
        "    # learning rate of 1. is default for this optimizer\n",
        "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.momentum = momentum\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If we use momentum\n",
        "        if self.momentum:\n",
        "            # If layer does not contain momentum arrays, create them\n",
        "            # filled with zeros\n",
        "            if not hasattr(layer, 'weight_momentums'):\n",
        "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "                # If there is no momentum array for weights\n",
        "                # The array doesn't exist for biases yet either.\n",
        "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "\n",
        "            # Build weight updates with momentum - take previous\n",
        "            # updates multiplied by retain factor and update with\n",
        "            # current gradients\n",
        "            weight_updates = \\\n",
        "                self.momentum * layer.weight_momentums - \\\n",
        "                self.current_learning_rate * layer.dweights\n",
        "            layer.weight_momentums = weight_updates\n",
        "\n",
        "            # Build bias updates\n",
        "            bias_updates = \\\n",
        "                self.momentum * layer.bias_momentums - \\\n",
        "                self.current_learning_rate * layer.dbias\n",
        "            layer.bias_momentums = bias_updates\n",
        "\n",
        "        # Vanilla SGD updates (as before momentum update)\n",
        "        else:\n",
        "            weight_updates = -self.current_learning_rate * \\\n",
        "                             layer.dweights\n",
        "            bias_updates = -self.current_learning_rate * \\\n",
        "                           layer.dbias\n",
        "\n",
        "        # Update weights and biases using either\n",
        "        # vanilla or momentum updates\n",
        "        layer.weights += weight_updates\n",
        "        layer.bias += bias_updates\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1"
      ],
      "metadata": {
        "id": "9-RtxkJCnZuH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NNLayer:\n",
        "  def __init__(self,input_dim,neurons=5,learning_rate=0.001):\n",
        "    self.weights = 0.1 * np.random.randn(input_dim, neurons)\n",
        "    self.bias = np.zeros((1,neurons))\n",
        "    #self.learning_rate=learning_rate\n",
        "  \n",
        "  def forward(self,X):\n",
        "    self.inputs=X\n",
        "    self.output = np.dot(self.inputs,self.weights) + self.bias\n",
        "  \n",
        "  def backward(self,dvalues):\n",
        "    #parameter gradiants\n",
        "    self.dweights=np.dot(self.inputs.T,dvalues)\n",
        "    self.dbias =np.sum(dvalues, axis = 0 , keepdims= True )\n",
        "    #gradiant on input\n",
        "    self.dinputs =np.dot(dvalues,self.weights.T)\n",
        "  \n",
        "  # def update_weights(self):\n",
        "  #   self.weights= self.weights - (self.learning_rate*self.dweights)\n",
        "  #   self.bias = self.bias - (self.learning_rate*self.bias)"
      ],
      "metadata": {
        "id": "HhTnC4S92jhQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plot \n",
        "\n",
        "# Get x values of the sine wave\n",
        "time = np.arange(0, 10, 0.4);\n",
        "# Amplitude of the sine wave is sine of a variable like time\n",
        "amplitude   = np.sin(time)"
      ],
      "metadata": {
        "id": "2E39HKI3J39p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a sine wave using time and amplitude obtained for the sine wave\n",
        "plot.plot(time, amplitude) \n",
        "\n",
        "# Give a title for the sine wave plot\n",
        "plot.title('Sine wave')\n",
        "\n",
        "# Give x axis label for the sine wave plot\n",
        "plot.xlabel('Time')\n",
        "\n",
        "# Give y axis label for the sine wave plot\n",
        "plot.ylabel('Amplitude = sin(time)')\n",
        "plot.grid(True, which='both')\n",
        "plot.axhline(y=0, color='k')\n",
        "plot.show()\n",
        "# Display the sine wave\n",
        "\n",
        "plot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ColiXYnBLA_4",
        "outputId": "ff567c03-3cf2-4461-d98a-bb3cea6ef71e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = time, amplitude"
      ],
      "metadata": {
        "id": "D4gN6-dRLNH1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(X)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "E0Yl9ep_QCSX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Linear layer with 1 input feature and 64 output values\n",
        "dense1 = NNLayer(1,32)\n",
        "\n",
        "#add a relu activator to the layer\n",
        "r_activator = Relu()\n",
        "\n",
        "#create an another layer with 128 input features and 64 output feature\n",
        "dense2 = NNLayer(32,16)\n",
        "\n",
        "#add another relu activator layer.\n",
        "r2_activator = Relu()\n",
        "\n",
        "#create an another layer with 64 input features and 1 output feature\n",
        "dense3 = NNLayer(16,1)\n",
        "\n",
        "#create a linear activator\n",
        "l_activator= LinearActivation()\n",
        "\n",
        "#create loss function\n",
        "loss= MSE()"
      ],
      "metadata": {
        "id": "S2fckqrYLZWQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train in loop\n",
        "optimizer = Optimizer_SGD(learning_rate=0.005, decay=1e-3)\n",
        "\n",
        "predictor_values={}\n",
        "for epoch in range(10000):\n",
        "  dense1.forward(X.reshape(25,1))\n",
        "  r_activator.forward(dense1.output)\n",
        "  dense2.forward(r_activator.output)\n",
        "  r2_activator.forward(dense2.output)\n",
        "  dense3.forward(r2_activator.output)\n",
        "  l_activator.forward(dense3.output)\n",
        "  loss_calculation= loss.forward(l_activator.outputs,y.reshape(25,1))\n",
        "  if epoch %100==0:\n",
        "    print(loss_calculation)\n",
        "  loss.backward(l_activator.outputs,y.reshape(25,1))\n",
        "  l_activator.backward(loss.dinputs)\n",
        "  dense3.backward(l_activator.dinputs)\n",
        "  r2_activator.backward(dense3.dinputs)\n",
        "  dense2.backward(r2_activator.dinputs)\n",
        "  r_activator.backward(dense2.dinputs)\n",
        "  dense1.backward(r_activator.dinputs)\n",
        "  optimizer.pre_update_params()\n",
        "  optimizer.update_params(dense1)\n",
        "  optimizer.update_params(dense2)\n",
        "  optimizer.update_params(dense3)\n",
        "  optimizer.post_update_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ja4GJRPL15K",
        "outputId": "75e7aea0-2477-4808-d932-4d314c848764"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4353277665789551\n",
            "0.43545815918859937\n",
            "0.4354410309692194\n",
            "0.43542757063543347\n",
            "0.4354158916583933\n",
            "0.435404684203468\n",
            "0.4353939494899189\n",
            "0.43538153641259014\n",
            "0.4353668883786439\n",
            "0.4353480346037831\n",
            "0.4353233408596155\n",
            "0.4352921797346621\n",
            "0.4352549958667348\n",
            "0.43521581723162583\n",
            "0.4351834728509694\n",
            "0.43517902405533293\n",
            "0.4352166982463184\n",
            "0.435297549108663\n",
            "0.43537134739837813\n",
            "0.4353770291965518\n",
            "0.43536345174783675\n",
            "0.4353535784715525\n",
            "0.4353437709533847\n",
            "0.4353340153704153\n",
            "0.43532459718694855\n",
            "0.4353153577831926\n",
            "0.4353069834203673\n",
            "0.43529980753622155\n",
            "0.4352948211497181\n",
            "0.4352923393086679\n",
            "0.43529351682402345\n",
            "0.4352987214159516\n",
            "0.435307156513283\n",
            "0.4353172128850432\n",
            "0.43532620801351185\n",
            "0.435331624829897\n",
            "0.4353317527862376\n",
            "0.43532873662645477\n",
            "0.43532717184502756\n",
            "0.43532569845060765\n",
            "0.4353242716760509\n",
            "0.4353228894954245\n",
            "0.4353215501100198\n",
            "0.4353202519062895\n",
            "0.4353189934336975\n",
            "0.4353177733630208\n",
            "0.43531659046907606\n",
            "0.4353154436207425\n",
            "0.4353143317689235\n",
            "0.4353132539367443\n",
            "0.43531220921146363\n",
            "0.43531119673771856\n",
            "0.43531021571181616\n",
            "0.4353092653768618\n",
            "0.43530834501855575\n",
            "0.43530745396153797\n",
            "0.4353065915661815\n",
            "0.43530575722575854\n",
            "0.43530495036391836\n",
            "0.43530417043243175\n",
            "0.4353034169091594\n",
            "0.4353026892962147\n",
            "0.43530198711829604\n",
            "0.43530130992116484\n",
            "0.4353006572702536\n",
            "0.4353000287493867\n",
            "0.435299423959605\n",
            "0.43529884251725337\n",
            "0.4352982840536847\n",
            "0.4352977482156641\n",
            "0.4352972346634381\n",
            "0.43529674306989574\n",
            "0.4352962731197939\n",
            "0.43529582450903576\n",
            "0.43529539694400143\n",
            "0.43529499014092105\n",
            "0.4352946038252904\n",
            "0.43529423773132414\n",
            "0.4352938916014436\n",
            "0.43529356518579676\n",
            "0.435293258241807\n",
            "0.43529297053374966\n",
            "0.4352927018323545\n",
            "0.43529245191442983\n",
            "0.4352922205625096\n",
            "0.43529200756452135\n",
            "0.43529181271347134\n",
            "0.435291635807149\n",
            "0.43529147664784745\n",
            "0.43529133504209744\n",
            "0.4352912108004203\n",
            "0.4352911037370893\n",
            "0.4352910136699075\n",
            "0.43529094041999605\n",
            "0.4352908838115933\n",
            "0.4352908436718663\n",
            "0.4352908198307304\n",
            "0.4352908121206795\n",
            "0.43529082037662464\n",
            "0.43529084443574123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(X, y)\n",
        "plt.plot(X,l_activator.outputs)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "igN840HPU7H6",
        "outputId": "5856cc45-ae6b-49c3-b723-5e3b6f1a1d68"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dense layer\n",
        "class Layer_Dense:\n",
        "\n",
        "    # Layer initialization\n",
        "    def __init__(self, n_inputs, n_neurons,\n",
        "                 weight_regularizer_l1=0, weight_regularizer_l2=0,\n",
        "                 bias_regularizer_l1=0, bias_regularizer_l2=0):\n",
        "        # Initialize weights and biases\n",
        "        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "        # Set regularization strength\n",
        "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
        "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
        "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
        "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs, weights and biases\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradients on parameters\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "        # Gradients on regularization\n",
        "        # L1 on weights\n",
        "        if self.weight_regularizer_l1 > 0:\n",
        "            dL1 = np.ones_like(self.weights)\n",
        "            dL1[self.weights < 0] = -1\n",
        "            self.dweights += self.weight_regularizer_l1 * dL1\n",
        "        # L2 on weights\n",
        "        if self.weight_regularizer_l2 > 0:\n",
        "            self.dweights += 2 * self.weight_regularizer_l2 * \\\n",
        "                             self.weights\n",
        "        # L1 on biases\n",
        "        if self.bias_regularizer_l1 > 0:\n",
        "            dL1 = np.ones_like(self.biases)\n",
        "            dL1[self.biases < 0] = -1\n",
        "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
        "        # L2 on biases\n",
        "        if self.bias_regularizer_l2 > 0:\n",
        "            self.dbiases += 2 * self.bias_regularizer_l2 * \\\n",
        "                            self.biases\n",
        "\n",
        "        # Gradient on values\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "\n",
        "# Dropout\n",
        "class Layer_Dropout:\n",
        "\n",
        "    # Init\n",
        "    def __init__(self, rate):\n",
        "        # Store rate, we invert it as for example for dropout\n",
        "        # of 0.1 we need success rate of 0.9\n",
        "        self.rate = 1 - rate\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Save input values\n",
        "        self.inputs = inputs\n",
        "        # Generate and save scaled mask\n",
        "        self.binary_mask = np.random.binomial(1, self.rate,\n",
        "                           size=inputs.shape) / self.rate\n",
        "        # Apply mask to output values\n",
        "        self.output = inputs * self.binary_mask\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradient on values\n",
        "        self.dinputs = dvalues * self.binary_mask\n",
        "\n",
        "# ReLU activation\n",
        "class Activation_ReLU:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Since we need to modify original variable,\n",
        "        # let's make a copy of values first\n",
        "        self.dinputs = dvalues.copy()\n",
        "\n",
        "        # Zero gradient where input values were negative\n",
        "        self.dinputs[self.inputs <= 0] = 0\n",
        "\n",
        "\n",
        "# Softmax activation\n",
        "class Activation_Softmax:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "\n",
        "        # Get unnormalized probabilities\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
        "                                            keepdims=True))\n",
        "        # Normalize them for each sample\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
        "                                            keepdims=True)\n",
        "\n",
        "        self.output = probabilities\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "\n",
        "        # Create uninitialized array\n",
        "        self.dinputs = np.empty_like(dvalues)\n",
        "\n",
        "        # Enumerate outputs and gradients\n",
        "        for index, (single_output, single_dvalues) in \\\n",
        "                enumerate(zip(self.output, dvalues)):\n",
        "            # Flatten output array\n",
        "            single_output = single_output.reshape(-1, 1)\n",
        "\n",
        "            # Calculate Jacobian matrix of the output\n",
        "            jacobian_matrix = np.diagflat(single_output) - \\\n",
        "                              np.dot(single_output, single_output.T)\n",
        "            # Calculate sample-wise gradient\n",
        "            # and add it to the array of sample gradients\n",
        "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
        "                                         single_dvalues)\n",
        "\n",
        "\n",
        "# Sigmoid activation\n",
        "class Activation_Sigmoid:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Save input and calculate/save output\n",
        "        # of the sigmoid function\n",
        "        self.inputs = inputs\n",
        "        self.output = 1 / (1 + np.exp(-inputs))\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Derivative - calculates from output of the sigmoid function\n",
        "        self.dinputs = dvalues * (1 - self.output) * self.output\n",
        "\n",
        "\n",
        "# Linear activation\n",
        "class Activation_Linear:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Just remember values\n",
        "        self.inputs = inputs\n",
        "        self.output = inputs\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # derivative is 1, 1 * dvalues = dvalues - the chain rule\n",
        "        self.dinputs = dvalues.copy()\n",
        "\n",
        "\n",
        "# SGD optimizer\n",
        "class Optimizer_SGD:\n",
        "\n",
        "    # Initialize optimizer - set settings,\n",
        "    # learning rate of 1. is default for this optimizer\n",
        "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.momentum = momentum\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If we use momentum\n",
        "        if self.momentum:\n",
        "\n",
        "            # If layer does not contain momentum arrays, create them\n",
        "            # filled with zeros\n",
        "            if not hasattr(layer, 'weight_momentums'):\n",
        "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "                # If there is no momentum array for weights\n",
        "                # The array doesn't exist for biases yet either.\n",
        "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "\n",
        "            # Build weight updates with momentum - take previous\n",
        "            # updates multiplied by retain factor and update with\n",
        "            # current gradients\n",
        "            weight_updates = \\\n",
        "                self.momentum * layer.weight_momentums - \\\n",
        "                self.current_learning_rate * layer.dweights\n",
        "            layer.weight_momentums = weight_updates\n",
        "\n",
        "            # Build bias updates\n",
        "            bias_updates = \\\n",
        "                self.momentum * layer.bias_momentums - \\\n",
        "                self.current_learning_rate * layer.dbiases\n",
        "            layer.bias_momentums = bias_updates\n",
        "\n",
        "        # Vanilla SGD updates (as before momentum update)\n",
        "        else:\n",
        "            weight_updates = -self.current_learning_rate * \\\n",
        "                             layer.dweights\n",
        "            bias_updates = -self.current_learning_rate * \\\n",
        "                           layer.dbiases\n",
        "\n",
        "        # Update weights and biases using either\n",
        "        # vanilla or momentum updates\n",
        "        layer.weights += weight_updates\n",
        "        layer.biases += bias_updates\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Adagrad optimizer\n",
        "class Optimizer_Adagrad:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache += layer.dweights**2\n",
        "        layer.bias_cache += layer.dbiases**2\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         layer.dweights / \\\n",
        "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        layer.dbiases / \\\n",
        "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "# RMSprop optimizer\n",
        "class Optimizer_RMSprop:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
        "                 rho=0.9):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.rho = rho\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.rho * layer.weight_cache + \\\n",
        "            (1 - self.rho) * layer.dweights**2\n",
        "        layer.bias_cache = self.rho * layer.bias_cache + \\\n",
        "            (1 - self.rho) * layer.dbiases**2\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         layer.dweights / \\\n",
        "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        layer.dbiases / \\\n",
        "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Adam optimizer\n",
        "class Optimizer_Adam:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
        "                 beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update momentum  with current gradients\n",
        "        layer.weight_momentums = self.beta_1 * \\\n",
        "                                 layer.weight_momentums + \\\n",
        "                                 (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * \\\n",
        "                               layer.bias_momentums + \\\n",
        "                               (1 - self.beta_1) * layer.dbiases\n",
        "        # Get corrected momentum\n",
        "        # self.iteration is 0 at first pass\n",
        "        # and we need to start with 1 here\n",
        "        weight_momentums_corrected = layer.weight_momentums / \\\n",
        "            (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / \\\n",
        "            (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + \\\n",
        "            (1 - self.beta_2) * layer.dweights**2\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + \\\n",
        "            (1 - self.beta_2) * layer.dbiases**2\n",
        "        # Get corrected cache\n",
        "        weight_cache_corrected = layer.weight_cache / \\\n",
        "            (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / \\\n",
        "            (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         weight_momentums_corrected / \\\n",
        "                         (np.sqrt(weight_cache_corrected) +\n",
        "                             self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                         bias_momentums_corrected / \\\n",
        "                         (np.sqrt(bias_cache_corrected) +\n",
        "                             self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Common loss class\n",
        "class Loss:\n",
        "\n",
        "    # Regularization loss calculation\n",
        "    def regularization_loss(self, layer):\n",
        "\n",
        "        # 0 by default\n",
        "        regularization_loss = 0\n",
        "\n",
        "        # L1 regularization - weights\n",
        "        # calculate only when factor greater than 0\n",
        "        if layer.weight_regularizer_l1 > 0:\n",
        "            regularization_loss += layer.weight_regularizer_l1 * \\\n",
        "                                   np.sum(np.abs(layer.weights))\n",
        "\n",
        "        # L2 regularization - weights\n",
        "        if layer.weight_regularizer_l2 > 0:\n",
        "            regularization_loss += layer.weight_regularizer_l2 * \\\n",
        "                                   np.sum(layer.weights * \\\n",
        "                                          layer.weights)\n",
        "\n",
        "\n",
        "        # L1 regularization - biases\n",
        "        # calculate only when factor greater than 0\n",
        "        if layer.bias_regularizer_l1 > 0:\n",
        "            regularization_loss += layer.bias_regularizer_l1 * \\\n",
        "                                   np.sum(np.abs(layer.biases))\n",
        "\n",
        "        # L2 regularization - biases\n",
        "        if layer.bias_regularizer_l2 > 0:\n",
        "            regularization_loss += layer.bias_regularizer_l2 * \\\n",
        "                                   np.sum(layer.biases * \\\n",
        "                                          layer.biases)\n",
        "\n",
        "        return regularization_loss\n",
        "\n",
        "    # Calculates the data and regularization losses\n",
        "    # given model output and ground truth values\n",
        "    def calculate(self, output, y):\n",
        "\n",
        "        # Calculate sample losses\n",
        "        sample_losses = self.forward(output, y)\n",
        "\n",
        "        # Calculate mean loss\n",
        "        data_loss = np.mean(sample_losses)\n",
        "\n",
        "        # Return loss\n",
        "        return data_loss\n",
        "\n",
        "\n",
        "# Cross-entropy loss\n",
        "class Loss_CategoricalCrossentropy(Loss):\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Number of samples in a batch\n",
        "        samples = len(y_pred)\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Probabilities for target values -\n",
        "        # only if categorical labels\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[\n",
        "                range(samples),\n",
        "                y_true\n",
        "            ]\n",
        "        # Mask values - only for one-hot encoded labels\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(\n",
        "                y_pred_clipped * y_true,\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "        # Losses\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return negative_log_likelihoods\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of labels in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        labels = len(dvalues[0])\n",
        "\n",
        "        # If labels are sparse, turn them into one-hot vector\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Softmax classifier - combined Softmax activation\n",
        "# and cross-entropy loss for faster backward step\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
        "\n",
        "    # Creates activation and loss function objects\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, y_true):\n",
        "        # Output layer's activation function\n",
        "        self.activation.forward(inputs)\n",
        "        # Set the output\n",
        "        self.output = self.activation.output\n",
        "        # Calculate and return loss value\n",
        "        return self.loss.calculate(self.output, y_true)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "\n",
        "        # If labels are one-hot encoded,\n",
        "        # turn them into discrete values\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "        # Copy so we can safely modify\n",
        "        self.dinputs = dvalues.copy()\n",
        "        # Calculate gradient\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Binary cross-entropy loss\n",
        "class Loss_BinaryCrossentropy(Loss):\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Calculate sample-wise loss\n",
        "        sample_losses = -(y_true * np.log(y_pred_clipped) +\n",
        "                          (1 - y_true) * np.log(1 - y_pred_clipped))\n",
        "        sample_losses = np.mean(sample_losses, axis=-1)\n",
        "\n",
        "        # Return losses\n",
        "        return sample_losses\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of outputs in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        outputs = len(dvalues[0])\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -(y_true / clipped_dvalues -\n",
        "                         (1 - y_true) / (1 - clipped_dvalues)) / outputs\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Mean Squared Error loss\n",
        "class Loss_MeanSquaredError(Loss):  # L2 loss\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Calculate loss\n",
        "        sample_losses = np.mean((y_true - y_pred)**2, axis=-1)\n",
        "\n",
        "        # Return losses\n",
        "        return sample_losses\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of outputs in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        outputs = len(dvalues[0])\n",
        "\n",
        "        # Gradient on values\n",
        "        self.dinputs = -2 * (y_true - dvalues) / outputs\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Mean Absolute Error loss\n",
        "class Loss_MeanAbsoluteError(Loss):  # L1 loss\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Calculate loss\n",
        "        sample_losses = np.mean(np.abs(y_true - y_pred), axis=-1)\n",
        "\n",
        "        # Return losses\n",
        "        return sample_losses\n",
        "\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of outputs in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        outputs = len(dvalues[0])\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = np.sign(y_true - dvalues) / outputs\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Create dataset\n",
        "X,y = X.reshape(25,1), y.reshape(25,1)\n",
        "# Create Dense layer with 1 input feature and 64 output values\n",
        "dense1 = Layer_Dense(1, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "# Create second Dense layer with 64 input features (as we take output\n",
        "# of previous layer here) and 64 output values\n",
        "dense2 = Layer_Dense(64, 64)\n",
        "\n",
        "# Create ReLU activation (to be used with Dense layer):\n",
        "activation2 = Activation_ReLU()\n",
        "\n",
        "# Create third Dense layer with 64 input features (as we take output\n",
        "# of previous layer here) and 1 output value\n",
        "dense3 = Layer_Dense(64, 1)\n",
        "\n",
        "# Create Linear activation:\n",
        "activation3 = Activation_Linear()\n",
        "\n",
        "# Create loss function\n",
        "loss_function = Loss_MeanSquaredError()\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = Optimizer_Adam(learning_rate=0.005, decay=1e-3)\n",
        "\n",
        "\n",
        "# Accuracy precision for accuracy calculation\n",
        "# There are no really accuracy factor for regression problem,\n",
        "# but we can simulate/approximate it. We'll calculate it by checking\n",
        "# how many values have a difference to their ground truth equivalent\n",
        "# less than given precision\n",
        "# We'll calculate this precision as a fraction of standard deviation\n",
        "# of all the ground truth values\n",
        "accuracy_precision = np.std(y) / 250\n",
        "\n",
        "# Train in loop\n",
        "for epoch in range(10001):\n",
        "\n",
        "    # Perform a forward pass of our training data through this layer\n",
        "    dense1.forward(X)\n",
        "\n",
        "    # Perform a forward pass through activation function\n",
        "    # takes the output of first dense layer here\n",
        "    activation1.forward(dense1.output)\n",
        "\n",
        "    # Perform a forward pass through second Dense layer\n",
        "    # takes outputs of activation function\n",
        "    # of first layer as inputs\n",
        "    dense2.forward(activation1.output)\n",
        "\n",
        "    # Perform a forward pass through activation function\n",
        "    # takes the output of second dense layer here\n",
        "    activation2.forward(dense2.output)\n",
        "\n",
        "    # Perform a forward pass through third Dense layer\n",
        "    # takes outputs of activation function of second layer as inputs\n",
        "    dense3.forward(activation2.output)\n",
        "\n",
        "    # Perform a forward pass through activation function\n",
        "    # takes the output of third dense layer here\n",
        "    activation3.forward(dense3.output)\n",
        "\n",
        "    # Calculate the data loss\n",
        "    data_loss = loss_function.calculate(activation3.output, y)\n",
        "\n",
        "    # Calculate regularization penalty\n",
        "    regularization_loss = \\\n",
        "        loss_function.regularization_loss(dense1) + \\\n",
        "        loss_function.regularization_loss(dense2) + \\\n",
        "        loss_function.regularization_loss(dense3)\n",
        "\n",
        "    # Calculate overall loss\n",
        "    loss = data_loss + regularization_loss\n",
        "\n",
        "    # Calculate accuracy from output of activation2 and targets\n",
        "    # To calculate it we're taking absolute difference between\n",
        "    # predictions and ground truth values and compare if differences\n",
        "    # are lower than given precision value\n",
        "    predictions = activation3.output\n",
        "    accuracy = np.mean(np.absolute(predictions - y) <\n",
        "                       accuracy_precision)\n",
        "\n",
        "    if not epoch % 100:\n",
        "        print(f'epoch: {epoch}, ' +\n",
        "              f'acc: {accuracy:.3f}, ' +\n",
        "              f'loss: {loss:.3f} (' +\n",
        "              f'data_loss: {data_loss:.3f}, ' +\n",
        "              f'reg_loss: {regularization_loss:.3f}), ' +\n",
        "              f'lr: {optimizer.current_learning_rate}')\n",
        "\n",
        "    # Backward pass\n",
        "    loss_function.backward(activation3.output, y)\n",
        "    activation3.backward(loss_function.dinputs)\n",
        "    dense3.backward(activation3.dinputs)\n",
        "    activation2.backward(dense3.dinputs)\n",
        "    dense2.backward(activation2.dinputs)\n",
        "    activation1.backward(dense2.dinputs)\n",
        "    dense1.backward(activation1.dinputs)\n",
        "\n",
        "    # Update weights and biases\n",
        "    optimizer.pre_update_params()\n",
        "    optimizer.update_params(dense1)\n",
        "    optimizer.update_params(dense2)\n",
        "    optimizer.update_params(dense3)\n",
        "    optimizer.post_update_params()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfVSM3u8pbYd",
        "outputId": "01fc1510-69e8-44b2-b857-f26bf19406bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, acc: 0.040, loss: 0.573 (data_loss: 0.573, reg_loss: 0.000), lr: 0.005\n",
            "epoch: 100, acc: 0.040, loss: 0.142 (data_loss: 0.142, reg_loss: 0.000), lr: 0.004549590536851684\n",
            "epoch: 200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.004170141784820684\n",
            "epoch: 300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.003849114703618168\n",
            "epoch: 400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0035739814152966403\n",
            "epoch: 500, acc: 0.280, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00333555703802535\n",
            "epoch: 600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0031269543464665416\n",
            "epoch: 700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.002942907592701589\n",
            "epoch: 800, acc: 0.160, loss: 0.142 (data_loss: 0.142, reg_loss: 0.000), lr: 0.0027793218454697055\n",
            "epoch: 900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0026329647182727752\n",
            "epoch: 1000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.002501250625312656\n",
            "epoch: 1100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0023820867079561697\n",
            "epoch: 1200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.002273760800363802\n",
            "epoch: 1300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.002174858634188778\n",
            "epoch: 1400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0020842017507294707\n",
            "epoch: 1500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0020008003201280513\n",
            "epoch: 1600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.001923816852635629\n",
            "epoch: 1700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.001852537977028529\n",
            "epoch: 1800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0017863522686673815\n",
            "epoch: 1900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0017247326664367024\n",
            "epoch: 2000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0016672224074691564\n",
            "epoch: 2100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0016134236850596968\n",
            "epoch: 2200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0015629884338855893\n",
            "epoch: 2300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0015156107911488332\n",
            "epoch: 2400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0014710208884966167\n",
            "epoch: 2500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0014289797084881396\n",
            "epoch: 2600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.001389274798555154\n",
            "epoch: 2700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0013517166801838335\n",
            "epoch: 2800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0013161358252171624\n",
            "epoch: 2900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0012823800974608873\n",
            "epoch: 3000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0012503125781445363\n",
            "epoch: 3100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0012198097096852891\n",
            "epoch: 3200, acc: 0.280, loss: 0.142 (data_loss: 0.142, reg_loss: 0.000), lr: 0.0011907597046915933\n",
            "epoch: 3300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0011630611770179114\n",
            "epoch: 3400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0011366219595362584\n",
            "epoch: 3500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0011113580795732384\n",
            "epoch: 3600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0010871928680147858\n",
            "epoch: 3700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0010640561821664183\n",
            "epoch: 3800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0010418837257762034\n",
            "epoch: 3900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0010206164523372118\n",
            "epoch: 4000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0010002000400080014\n",
            "epoch: 4100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0009805844283192783\n",
            "epoch: 4200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0009617234083477593\n",
            "epoch: 4300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0009435742592942063\n",
            "epoch: 4400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0009260974254491572\n",
            "epoch: 4500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0009092562284051646\n",
            "epoch: 4600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.000893016610108948\n",
            "epoch: 4700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0008773469029654326\n",
            "epoch: 4800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.000862217623728229\n",
            "epoch: 4900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0008476012883539582\n",
            "epoch: 5000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0008334722453742291\n",
            "epoch: 5100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0008198065256599442\n",
            "epoch: 5200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0008065817067268914\n",
            "epoch: 5300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0007937767899666614\n",
            "epoch: 5400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0007813720893889669\n",
            "epoch: 5500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0007693491306354824\n",
            "epoch: 5600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0007576905591756327\n",
            "epoch: 5700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0007463800567248844\n",
            "epoch: 5800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0007354022650389764\n",
            "epoch: 5900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0007247427163357008\n",
            "epoch: 6000, acc: 0.400, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.000714387769681383\n",
            "epoch: 6100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0007043245527539089\n",
            "epoch: 6200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006945409084595084\n",
            "epoch: 6300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006850253459377996\n",
            "epoch: 6400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006757669955399379\n",
            "epoch: 6500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006667555674089878\n",
            "epoch: 6600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006579813133307014\n",
            "epoch: 6700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006494349915573451\n",
            "epoch: 6800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006411078343377356\n",
            "epoch: 6900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00063299151791366\n",
            "epoch: 7000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006250781347668457\n",
            "epoch: 7100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006173601679219657\n",
            "epoch: 7200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006098304671301379\n",
            "epoch: 7300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0006024822267743102\n",
            "epoch: 7400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005953089653530181\n",
            "epoch: 7500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.000588304506412519\n",
            "epoch: 7600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005814629608093965\n",
            "epoch: 7700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005747787101965744\n",
            "epoch: 7800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005682463916354131\n",
            "epoch: 7900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005618608832453085\n",
            "epoch: 8000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00055561729081009\n",
            "epoch: 8100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005495109352676119\n",
            "epoch: 8200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005435373410153278\n",
            "epoch: 8300, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005376922249704269\n",
            "epoch: 8400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005319714863283328\n",
            "epoch: 8500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005263711969681019\n",
            "epoch: 8600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005208875924575476\n",
            "epoch: 8700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005155170636148056\n",
            "epoch: 8800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005102561485865905\n",
            "epoch: 8900, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005051015254066068\n",
            "epoch: 9000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0005000500050005\n",
            "epoch: 9100, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0004950985246063966\n",
            "epoch: 9200, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0004902441415825081\n",
            "epoch: 9300, acc: 0.360, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0004854840275754928\n",
            "epoch: 9400, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.0004808154630252909\n",
            "epoch: 9500, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00047623583198399844\n",
            "epoch: 9600, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00047174261722804036\n",
            "epoch: 9700, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00046733339564445275\n",
            "epoch: 9800, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00046300583387350687\n",
            "epoch: 9900, acc: 0.360, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00045875768419121016\n",
            "epoch: 10000, acc: 0.440, loss: 0.141 (data_loss: 0.141, reg_loss: 0.000), lr: 0.00045458678061641964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(X, y)\n",
        "plt.plot(X, activation3.output)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "wgRboffBqHqF",
        "outputId": "60fec1da-e523-40a3-b342-391494374cbf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}